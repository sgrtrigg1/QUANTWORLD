\chapter{Results and Discussion}
\label{ch:results}

This chapter presents the empirical results of the forecasting models implemented in this dissertation and provides a comparative discussion of their performance. The results are organised around four key components: supervised regression, market-regime classification, unsupervised clustering and deep-learning models. Taken together, these analyses provide a comprehensive assessment of how classical, machine-learning and deep-learning techniques behave when applied to real financial time series.

Across all experiments, several themes emerge consistently: the impact of non-stationarity, the dominance of noise in daily data, the importance of regime structure and the trade-off between model flexibility and robustness.

\section{Supervised Regression Results}

\subsection{Global OLS Performance}
The global OLS regression model exhibited consistently poor predictive performance, confirming that fixed-parameter linear models cannot capture the dynamics of financial markets. Specifically:
\begin{itemize}
    \item the fitted slope underestimated upward momentum periods,
    \item it overestimated downward swings,
    \item it failed to adapt to regime transitions.
\end{itemize}

The resulting high systematic bias is evident in the divergence between predicted and realised prices (Figure~\ref{fig:global_ols}). Global OLS also produced the highest MAE and RMSE among all regression techniques. These findings reinforce the widely held view that global trend-fitting is unsuitable for short-term financial prediction.

\subsection{Sliding-Window OLS Performance}
Sliding-window OLS substantially improved performance by adapting to local market structure. Bias decreased significantly relative to the global model, especially during:
\begin{itemize}
    \item short-term trending periods,
    \item momentum reversals,
    \item early-stage volatility events.
\end{itemize}

Figure~\ref{fig:rolling_forecast} illustrates the model’s ability to track price direction more effectively than global OLS. However, performance depends critically on window size.

\paragraph{Window Size Effects.}
\begin{itemize}
    \item \textbf{Short windows (e.g.\ 40 days)}: very low bias, high variance, prone to noise.
    \item \textbf{Medium windows (e.g.\ 80 days)}: best overall performance, lowest combined error.
    \item \textbf{Long windows (e.g.\ 120 days)}: low variance but high bias; slow to adapt to new regimes.
\end{itemize}

This behaviour aligns closely with the bias–variance trade-off discussed in Chapter~\ref{ch:supervised}.

\section{Bias–Variance Trade-Off Results}
The empirical bias–variance curve (Figure~\ref{fig:bias_variance_curve}) displays a smooth monotonic relationship: as window length increases, bias increases, while variance decreases. A minimum-error region emerges between 60 and 90 days, indicating that local linear models strike an optimal balance when they incorporate enough past data to smooth noise while still being responsive to trend changes.

These results show that even simple models can perform competitively in finance when tuned appropriately for non-stationary signals.

\section{Market-Regime Classification Results}

\subsection{Classifier Accuracy and Confusion Matrix}
Logistic regression was used to classify bull, bear and sideways regimes. Overall, the classifier performed strongly:
\begin{itemize}
    \item sustained bull and bear regimes were identified accurately,
    \item sideways regimes showed moderate accuracy,
    \item most errors occurred near regime boundaries.
\end{itemize}

The confusion matrix (Figure~\ref{fig:confusion_matrix}) shows that:
\begin{itemize}
    \item bull $\rightarrow$ bear misclassifications were rare,
    \item bear $\rightarrow$ bull misclassifications occurred mainly during sharp reversals,
    \item sideways regimes overlapped significantly with both other classes.
\end{itemize}

These results validate logistic regression as a reliable baseline for regime identification.

\subsection{Feature Contributions}
The most influential features were:
\begin{itemize}
    \item rolling returns (trend strength),
    \item rolling volatility (risk level),
    \item moving-average deviation (momentum deviation),
    \item RSI (short-term oscillation).
\end{itemize}

These features align with financial intuition, suggesting that the classifier captures meaningful structure rather than artefacts of noise.

\section{Unsupervised Learning Results}

\subsection{K-Means Clustering Results}
K-Means applied to returns, volatility and technical indicators produced three clear clusters aligned with bull, bear and sideways regimes:
\begin{itemize}
    \item high-volatility, negative-return cluster $\rightarrow$ bear states,
    \item low-volatility, positive-return cluster $\rightarrow$ bull states,
    \item neutral-volatility, oscillating-return cluster $\rightarrow$ sideways phases.
\end{itemize}

Figure~\ref{fig:kmeans_regimes} visualises the separation between clusters. Notably, unsupervised labels strongly matched supervised labels, providing independent validation of regime structure.

\subsection{PCA Results: Latent Market Factors}
Principal Component Analysis revealed the following latent structures:
\begin{itemize}
    \item \textbf{PC1}: market trend factor,
    \item \textbf{PC2}: volatility factor,
    \item \textbf{PC3}: liquidity/momentum factor.
\end{itemize}

The first two components explained a substantial proportion of total variance (Figure~\ref{fig:pca_scree}). Projecting observations onto PC1–PC2 space (Figure~\ref{fig:pca_biplot}) produced visually separable clusters that matched K-Means outputs and logistic-regression labels. This convergence demonstrates that regime structure is deeply embedded in the fundamental variance components of market data.

\subsection{Regime Alignment}
A key result is the alignment between:
\begin{itemize}
    \item supervised classification,
    \item unsupervised clustering,
    \item PCA projections,
    \item rolling-slope analysis.
\end{itemize}

This triangulation significantly strengthens the empirical claims of the dissertation.

\section{Deep Learning Results}

\subsection{ANN Performance}
The ANN provided modest improvements over linear baselines:
\begin{itemize}
    \item MAE decreased slightly relative to sliding-window OLS,
    \item directional responsiveness improved during trending markets,
    \item instability increased during high-volatility periods.
\end{itemize}

These results confirm that while ANNs can capture non-linearities, their performance remains constrained by noise-dominated daily data.

\subsection{LSTM Performance}
The LSTM captured sequential dependencies more effectively than the ANN:
\begin{itemize}
    \item performance improved in sustained bull and bear markets,
    \item accuracy deteriorated in sideways markets,
    \item overfitting risks increased on limited datasets,
    \item long-range dependencies were captured only with well-tuned window lengths.
\end{itemize}

These findings align with prior work showing that LSTMs struggle when signal-to-noise ratios are low.

\subsection{Model Comparison}
The overall performance hierarchy was:
\begin{enumerate}
    \item Sliding-window OLS (medium windows): best trade-off and stability,
    \item Logistic regression: robust regime classification,
    \item LSTM: strong in trending regimes, inconsistent elsewhere,
    \item ANN: moderate non-linear performance,
    \item Global OLS: weakest performer.
\end{enumerate}

\textbf{Complexity does not guarantee superior forecasting performance}. Predictive accuracy is often constrained more by the data than by model architecture.

\section{Discussion of Findings}

\subsection{Non-Stationarity Dominates Model Behaviour}
All models struggled during regime transitions and volatility spikes. Adaptive approaches (rolling windows, regime-aware models) consistently outperformed static ones.

\subsection{Regime Structure Is Strong and Reproducible}
Across all modelling techniques, three regimes emerged consistently: upward-trending, downward-trending and sideways/consolidation. This demonstrates that regime structure is intrinsic to market behaviour.

\subsection{Sliding Windows Are Surprisingly Effective}
Rolling OLS models performed strongly because they:
\begin{itemize}
    \item adapted quickly to structural changes,
    \item avoided overfitting,
    \item captured short-term trend dynamics,
    \item remained stable in noisy conditions.
\end{itemize}

This is an academically significant result.

\subsection{Deep Learning Is Limited by Data, Not by Architecture}
Daily stock data:
\begin{itemize}
    \item contain limited samples,
    \item exhibit weak sequential dependencies,
    \item produce unstable reward dynamics.
\end{itemize}

Thus, deep models offer only marginal gains unless supplied with richer datasets (e.g.\ intraday microstructure).

\subsection{Consistency Across Approaches Strengthens Conclusions}
The agreement between rolling slopes, logistic regression, K-Means clustering and PCA projections provides strong evidence that the modelling pipeline captures meaningful regime structure rather than noise artefacts.
